<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN" "JATS-archivearticle1-mathml3.dtd"> 
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName JATS-journalpublishing1.dtd?><?SourceDTD.Version 1.1?><?ConverterInfo.XSLTName jp2nlmx2.xsl?><?ConverterInfo.Version 1?><front><journal-meta><journal-id journal-id-type="nlm-ta">Sensors (Basel)</journal-id><journal-id journal-id-type="iso-abbrev">Sensors (Basel)</journal-id><journal-id journal-id-type="publisher-id">sensors</journal-id><journal-title-group><journal-title>Sensors (Basel, Switzerland)</journal-title></journal-title-group><issn pub-type="epub">1424-8220</issn><publisher><publisher-name>MDPI</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">6891284</article-id><article-id pub-id-type="doi">10.3390/s19224980</article-id><article-id pub-id-type="publisher-id">sensors-19-04980</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Design of a Low-Cost Indoor Navigation System for Food Delivery Robot Based on Multi-Sensor Information Fusion</article-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-3588-792X</contrib-id><name><surname>Sun</surname><given-names>Yunlong</given-names></name><xref ref-type="aff" rid="af1-sensors-19-04980">1</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0001-8803-910X</contrib-id><name><surname>Guan</surname><given-names>Lianwu</given-names></name><xref ref-type="aff" rid="af1-sensors-19-04980">1</xref><xref rid="c1-sensors-19-04980" ref-type="corresp">*</xref></contrib><contrib contrib-type="author"><name><surname>Chang</surname><given-names>Zhanyuan</given-names></name><xref ref-type="aff" rid="af2-sensors-19-04980">2</xref><xref rid="c1-sensors-19-04980" ref-type="corresp">*</xref></contrib><contrib contrib-type="author"><name><surname>Li</surname><given-names>Chuanjiang</given-names></name><xref ref-type="aff" rid="af2-sensors-19-04980">2</xref></contrib><contrib contrib-type="author"><name><surname>Gao</surname><given-names>Yanbin</given-names></name><xref ref-type="aff" rid="af1-sensors-19-04980">1</xref></contrib></contrib-group><aff id="af1-sensors-19-04980"><label>1</label>College of Automation, Harbin Engineering University, Harbin 150001, China; <email>sunyunlong@hrbeu.edu.cn</email> (Y.S.); <email>gaoyanbin@hrbeu.edu.cn</email> (Y.G.)</aff><aff id="af2-sensors-19-04980"><label>2</label>College of Information, Mechanical and Electrical Engineering, Shanghai Normal University, Shanghai 200234, China; <email>licj@shnu.edu.cn</email></aff><author-notes><corresp id="c1-sensors-19-04980"><label>*</label>Correspondence: <email>guanlianwu@hrbeu.edu.cn</email> (L.G.); <email>changzhanyuan@shnu.edu.cn</email> (Z.C.); Tel.: +86-451-8251-8042 (L.G.)</corresp></author-notes><pub-date pub-type="epub"><day>15</day><month>11</month><year>2019</year></pub-date><pub-date pub-type="collection"><month>11</month><year>2019</year></pub-date><volume>19</volume><issue>22</issue><elocation-id>4980</elocation-id><history><date date-type="received"><day>07</day><month>10</month><year>2019</year></date><date date-type="accepted"><day>13</day><month>11</month><year>2019</year></date></history><permissions><copyright-statement>&#x000a9; 2019 by the authors.</copyright-statement><copyright-year>2019</copyright-year><license license-type="open-access"><license-p>Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>).</license-p></license></permissions><abstract><p>As the restaurant industry is facing labor shortage issues, the use of meal delivery robots instead of waiters/waitresses not only allows the customers to experience the impact of robot technology but also benefits the restaurant business financially by reducing labor costs. Most existing meal delivery robots employ magnetic navigation technologies, which require magnetic strip installation and changes to the restaurant decor. Once the moving path is changed, the magnetic strips need to be re-laid. This study proposes multisource information fusion, i.e., the fusion of ultra-wide band positioning technology with an odometer and a low-cost gyroscope accelerometer, to achieve the positioning of a non-rail meal delivery robot with navigation. By using a low-cost electronic compass and gyroscope accelerometer, the delivery robot can move along a fixed orbit in a flexible and cost-effective manner with steering control. Ultra-wide band (UWB) and track estimation algorithm are combined by extended Kalman filter (EKF), and the positioning error after fusion is about 15 cm, which is accepted by restaurants. In summary, the proposed approach has some potential for commercial applications.</p></abstract><kwd-group><kwd>wheeled robot</kwd><kwd>robot control</kwd><kwd>odometer positioning method</kwd><kwd>ultra-wide band localization</kwd><kwd>extended Kalman filter</kwd></kwd-group></article-meta></front><body><sec sec-type="intro" id="sec1-sensors-19-04980"><title>1. Introduction</title><p>Food and beverage marketing statistics have shown that the value of the Chinese food industry reached 2T yuan in 2015. However, with rising labor costs, the profit margins of the food and beverage industry have remained low. In China, the gradual increase in labor costs has led to labor shortages, contributing toward the replacement of humans with robots. Such a policy not only reduces labor costs but also improves efficiency and increases corporate earnings [<xref rid="B1-sensors-19-04980" ref-type="bibr">1</xref>]. For example, at restaurants, delivery robots not only reduce labor costs but also increase the automatic control performance and practicality of the robots. Compared to industrial robots, service robots are used in social settings, hence, their precision and safety requirements are higher. Most service robots are designed for a particular environment to assist humans in accomplishing some specific tasks, e.g., restaurant diners.</p><p>The vast majority of commercial delivery robots are controlled by magnetic induction or optical tracking. Such robots consist of a head unit, trunk assembly, and robotic arm. The literature [<xref rid="B2-sensors-19-04980" ref-type="bibr">2</xref>] proposed a daily life assistance robot with projection function. The literature [<xref rid="B3-sensors-19-04980" ref-type="bibr">3</xref>] designed a front-desk service robot named &#x0201c;Black Bot&#x0201d; with voice control function. The robotic arm usually holds an object and its main body moves along a guide rail. The main body consists of a controller, a battery, motor drives, and a voice interface. The guide rail with magnetic strips can reflect photoelectric beams. Positioning and obstacle avoidance are achieved by a tracking device in the body. The disadvantages of this approach are as follows. Poor environmental adaptability: In a barrier-free environment in the laboratory, the robot performs well. However, in an actual restaurant, its anti-interference ability is poor [<xref rid="B4-sensors-19-04980" ref-type="bibr">4</xref>]. Moreover, it is vulnerable to light and surface stains. Such external interference can severely affect the operation of the robot. High installation and maintenance costs: Current delivery robots work only in accordance with a preset trajectory, which has to be installed along a track on the ground. This will not only affect the layout and appearance of the restaurant but also increase installation costs. Inflexible service schedule: If the moving schedule is changed, the path needs to be re-laid, which is usually infeasible.</p><p>Indoor location-based services are challenging owing to the vast coverage required and the scalability of positioning systems [<xref rid="B5-sensors-19-04980" ref-type="bibr">5</xref>]. At present, the mainstream interior positioning technologies include magnetic navigation, simultaneous localization and mapping (SLAM) [<xref rid="B6-sensors-19-04980" ref-type="bibr">6</xref>,<xref rid="B7-sensors-19-04980" ref-type="bibr">7</xref>], Wi-Fi positioning, radio frequency identification (RFID) positioning, and UWB positioning [<xref rid="B8-sensors-19-04980" ref-type="bibr">8</xref>,<xref rid="B9-sensors-19-04980" ref-type="bibr">9</xref>]. There have been many studies on Wi-Fi indoor positioning technology. Xujian and Hao [<xref rid="B10-sensors-19-04980" ref-type="bibr">10</xref>] proposed an improved Kalman-filtering-based WiFi indoor positioning algorithm. Zhang et al. [<xref rid="B11-sensors-19-04980" ref-type="bibr">11</xref>] presented a domain-clustering-based WiFi indoor positioning algorithm. In UWB field, Ubisense Co. Ltd. from the UK has produced the UbisB 7000 positioning system based on UWB technology, which uses Time Difference of Arrival (TDOA) and Activity on Arrow (AOA) hybrid positioning algorithm to achieve 15 cm accuracy in typical applications. AETHER WIRE &#x00026; LOCATION Co. Ltd. of the United States introduced the localizers system with a range accuracy of 1cm and a node volume of 8 mm [<xref rid="B12-sensors-19-04980" ref-type="bibr">12</xref>]. Their common shortcoming is that they are expensive. When these indoor positioning technologies are used independently, they tend to have poor positioning accuracy and low reliability. In addition, they are time-consuming and entail high costs. Although guiding a robot using magnetic navigation as a means of positioning does not appear to involve positioning errors, the robot stops when it encounters obstacles and it cannot make an autonomous detour. In addition, when an out-of-orbit accident occurs, the operation has to be resumed by the staff, and the flexibility is low. Another common method for robot positioning is based on SLAM, which allows independent navigation, obstacle avoidance, and path planning. Compared with magnetic navigation, the flexibility of the feeding robot is improved considerably. However, when faced with many obstacles or surrounded by humans, the radar cannot scan the surrounding environment sufficiently, resulting in a loss of coordinates. Wi-Fi [<xref rid="B13-sensors-19-04980" ref-type="bibr">13</xref>] and RFID technologies cannot meet the precision requirements of indoor positioning for meal delivery robots. To improve accuracy, researchers have proposed the use of UWB technology. UWB signals have the advantages of high penetration, high multi-path resolution, and low transmitting power. UWB positioning can achieve centimeter-scale location accuracy without accumulating errors [<xref rid="B14-sensors-19-04980" ref-type="bibr">14</xref>,<xref rid="B15-sensors-19-04980" ref-type="bibr">15</xref>]. Considering the environment in a restaurant, the use of only UWB technology results in low positioning accuracy, e.g., around 30&#x02013;40 cm. In this situation, using an inertial measurement unit (IMU) is a good choice. The Inertial Navigation System (INS) has good short-term accuracy and does not rely on any external sources for determining position and attitude. Guan et al. [<xref rid="B16-sensors-19-04980" ref-type="bibr">16</xref>] presented a low-cost, high-integrated, and small-size mems inertial navigation system. Combining an IMU with UWB technology can improve the positioning accuracy [<xref rid="B17-sensors-19-04980" ref-type="bibr">17</xref>,<xref rid="B18-sensors-19-04980" ref-type="bibr">18</xref>]. However, the stability is poor while turning or changing speed and the overall accuracy of the system is thus reduced [<xref rid="B19-sensors-19-04980" ref-type="bibr">19</xref>,<xref rid="B20-sensors-19-04980" ref-type="bibr">20</xref>]. In addition to the fusion of UWB and IMU technologies, visual odometer correction can improve the positioning accuracy. However, it increases the hardware cost. Moreover, the installation is complex, and the system is sensitive to light [<xref rid="B21-sensors-19-04980" ref-type="bibr">21</xref>]. Moreover, a large number of network nodes are required to complete a wide range of indoor target tracking tasks, which is bound to introduce concerns related to network structure optimization as well as multi-node/multi-cluster coordination and communication. Among navigation technologies without beacons, the most commonly used method is the analysis of the pedestrian trajectory by an inertial navigation system [<xref rid="B22-sensors-19-04980" ref-type="bibr">22</xref>]. To overcome the shortcomings of a single technology for interior positioning, it is necessary to integrate such technology with multi-sensor information to realize a high-precision, high-reliability, and low-cost positioning system.</p><p>This paper presents a meal delivery robot with positioning and navigation control based on the fusion of information from multiple sources or technologies, namely UWB positioning, an odometer, a low-cost gyroscope accelerometer, and an electronic compass. We establish the kinematics model of the delivery robot. To improve the positioning accuracy and stability effectively, we fuse the positioning results of the UWB system with those of odometer and a dead reckoning algorithm. The algorithm used for the fusion is an extended Kalman filter (EKF) fusion algorithm, which is suitable for discrete systems in the presence of Gaussian white noise. The designed robot can move along the preset path without the need for laying a navigation track. Moreover, when the restaurant changes its layout, we need to modify only the default track in the software.</p><p>This paper is organized as follows: <xref ref-type="sec" rid="sec1-sensors-19-04980">Section 1</xref> introduces the current situation of service robots at home and abroad and extends to the food delivery machine. In addition, the research status of indoor positioning technology is expounded, and the advantages and disadvantages of various positioning technologies are roughly compared. At the same time, the main multi-sensor information fusion algorithms at home and abroad are introduced. <xref ref-type="sec" rid="sec2-sensors-19-04980">Section 2</xref> introduces the positioning system design, which including the robot modeling, odometer positioning method, and optimization, UWB positioning method and EKF fusion of the previous two algorithms. At last, meal delivery robot trajectory control is introduced. <xref ref-type="sec" rid="sec3-sensors-19-04980">Section 3</xref> introduces the experiment and result analysis. The experiment is divided into three parts: The UWB positioning system experiment, coordinate calculation experiment for improved odometer positioning method, and the EKF fusion algorithm coordinate fusion experiment. The previous two experiments obtained the positioning results of the UWB positioning system and the improved odometer positioning method, respectively, and analysis of the error and source. Finally, the EKF fusion algorithm is used to fuse the positioning results of the two algorithms to obtain better positioning results with better accuracy and stability. <xref ref-type="sec" rid="sec4-sensors-19-04980">Section 4</xref> is the conclusion. By this algorithm, the trajectory error of the food delivery robot can be less than 15 cm, whose precision is acceptable for the application field such as in a restaurant.</p></sec><sec id="sec2-sensors-19-04980"><title>2. Positioning System Design</title><p>The delivery robot control system consists of a control panel, motors and motor drives, power supplies, UWB positioning systems, an infrared and ultrasonic sensor module, and a gyroscope attitude sensor.</p><p>The robot has three wheels. Two of the three wheels are motor-driven, while the third is a follower. Each motor-driven wheel is connected to a 90-W servo motor via a gearbox. Each motor drive is associated with an encoder data output. To realize autonomous navigation control of the robot, the control panel employs a STM32 [<xref rid="B23-sensors-19-04980" ref-type="bibr">23</xref>] system to receive data from the infrared sensor, ultrasonic sensor, gyroscope accelerometer, and electronic compass in order to avoid obstacles, transmit information through the server (host computer), and control the motors according to the positioning information. The system also employs a low-cost IMU (9DoF-RazorIMU) [<xref rid="B24-sensors-19-04980" ref-type="bibr">24</xref>], which provides the heading angle for robot steering.</p><p>As shown in <xref ref-type="fig" rid="sensors-19-04980-f001">Figure 1</xref>, the server calculates the robot&#x02019;s current location in accordance with the UWB signal and then calculates the direction and speed of the robot according to the user-preset target point. The embedded firmware in the main control board modifies the speed of the left and right wheels to steer the robot, while the electronic compass provides angle feedback to achieve more precise steering control. Furthermore, the embedded firmware acquires signals from the obstacle avoidance sensor in real time. Thus, the robot operates an emergency brake within a certain distance from the obstacles. Obstacle avoidance is set as the highest priority to ensure the safe operation of the robot.</p><p>The meal delivery robot positioning system consists of a combination of UWB positioning and odometer positioning systems.</p><sec id="sec2dot1-sensors-19-04980"><title>2.1. Traditional Odometer Positioning Method</title><p>The odometer signals are provided by the left and right motors, i.e., the odometer records the number of motor rotations and then performs calculations based on the real-time location. This is a low-cost design.</p><p>It is assumed that the trajectory of the food delivery robot is a segment of an arc, and if the rotation speed of the food delivery robot is zero, which means that the speeds of the left and right wheels are equal, the trajectory of movement of the robot is a straight line. Assume that the two-wheel distance of the food delivery robot is <inline-formula><mml:math id="mm1"><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>L</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> and the center of its movement mechanism (the center of the two rounds of connection) is point p. After a certian time, the robot moves to point p&#x02019;, and the arc lengths of the left and right wheels increase, as shown in <xref ref-type="fig" rid="sensors-19-04980-f002">Figure 2</xref>.</p><p>If the extension lines of the two wheels when the robot is at points p and p&#x02019; intersect, their intersection point is the center of the circle where the delivery robot&#x02019;s movement trajectory is located. The radius of the circle is <inline-formula><mml:math id="mm2"><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:math></inline-formula>, the actual walking arc length is <inline-formula><mml:math id="mm3"><mml:mrow><mml:mrow><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>S</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>, the left wheel moving arc length is <inline-formula><mml:math id="mm4"><mml:mrow><mml:mrow><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, the left wheel moving arc length is <inline-formula><mml:math id="mm5"><mml:mrow><mml:mrow><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and the changing angle is <inline-formula><mml:math id="mm6"><mml:mrow><mml:mi>&#x003b1;</mml:mi></mml:mrow></mml:math></inline-formula>. <xref ref-type="fig" rid="sensors-19-04980-f003">Figure 3</xref>a shows the changing central angle of the robot in time <italic>t</italic>. <xref ref-type="fig" rid="sensors-19-04980-f003">Figure 3</xref>b shows the changing heading angle of the robot in time <italic>t</italic>.</p><p>The following formula can be obtained by arc length calculation:<disp-formula id="FD1-sensors-19-04980"><label>(1)</label><mml:math id="mm7"><mml:mrow><mml:mrow><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>R</mml:mi><mml:mi>&#x003b1;</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>R</mml:mi><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mi>L</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>&#x003b1;</mml:mi></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD2-sensors-19-04980"><label>(2)</label><mml:math id="mm8"><mml:mrow><mml:mrow><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>S</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>R</mml:mi><mml:mo>+</mml:mo><mml:mi>L</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mi>r</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Equation (1) can be rewritten as Equation (2):<disp-formula id="FD3-sensors-19-04980"><label>(3)</label><mml:math id="mm9"><mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>L</mml:mi><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Thus, Equation (3) can be obtained:<disp-formula id="FD4-sensors-19-04980"><label>(4)</label><mml:math id="mm10"><mml:mrow><mml:mrow><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>&#x003b8;</mml:mi><mml:mo>=</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mrow><mml:mi>R</mml:mi></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mi>r</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>L</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm11"><mml:mrow><mml:mrow><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>&#x003b8;</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> is the changing angle of the delivery robot.</p><p>When the distance traveled by the delivery robot is extremely small, the incremental arc length <inline-formula><mml:math id="mm12"><mml:mrow><mml:mrow><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>S</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> is equivalent to a small straight line of length <inline-formula><mml:math id="mm13"><mml:mrow><mml:mrow><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>. The following formula can be deduced from <xref ref-type="fig" rid="sensors-19-04980-f003">Figure 3</xref>b.
<disp-formula id="FD5-sensors-19-04980"><label>(5)</label><mml:math id="mm14"><mml:mrow><mml:mrow><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>d</mml:mi><mml:mi>cos</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>&#x003b8;</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD6-sensors-19-04980"><label>(6)</label><mml:math id="mm15"><mml:mrow><mml:mrow><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>d</mml:mi><mml:mi>sin</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>&#x003b8;</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>The final coordinates <italic>x</italic>, <italic>y</italic> and the heading angle <inline-formula><mml:math id="mm16"><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow></mml:math></inline-formula> can be expressed as follows:<disp-formula id="FD7-sensors-19-04980"><label>(7)</label><mml:math id="mm17"><mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>d</mml:mi><mml:mi>cos</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>&#x003b8;</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD8-sensors-19-04980"><label>(8)</label><mml:math id="mm18"><mml:mrow><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mi>y</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mi>y</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>d</mml:mi><mml:mi>sin</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>&#x003b8;</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD9-sensors-19-04980"><label>(9)</label><mml:math id="mm19"><mml:mrow><mml:mrow><mml:mi>&#x003b8;</mml:mi><mml:mo>=</mml:mo><mml:mi>&#x003b8;</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>&#x003b8;</mml:mi><mml:mo>=</mml:mo><mml:mi>&#x003b8;</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mi>r</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>L</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>From the analysis presented above, if the delivery robot is described by the function <inline-formula><mml:math id="mm20"><mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>&#x003b8;</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> at point p&#x02019;, the following equation can be obtained:<disp-formula id="FD10-sensors-19-04980"><label>(10)</label><mml:math id="mm21"><mml:mrow><mml:mrow><mml:msup><mml:mi>p</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>&#x003b8;</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mi>x</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>y</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>&#x003b8;</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mi>r</mml:mi></mml:msub></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:mi>cos</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>&#x003b8;</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mi>r</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mi>L</mml:mi></mml:mrow></mml:mfrac><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>y</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mi>r</mml:mi></mml:msub></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:mi>sin</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>&#x003b8;</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mi>r</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mi>L</mml:mi></mml:mrow></mml:mfrac><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>&#x003b8;</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>L</mml:mi></mml:mrow></mml:mfrac></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p></sec><sec id="sec2dot2-sensors-19-04980"><title>2.2. Improved Odometer Positioning Method</title><p>To address the accumulated error of the traditional odometer positioning method and inability of the system to accurately reflect the coordinates and heading angle of the delivery robot under slippery and low-friction conditions, an improved odometer positioning method is adopted, which uses an external sensor to measure the heading angle and angle change during the sampling period on the basis of photoelectric signals.</p><p>This method uses the heading angle &#x003b1; measured by an IMU, because the heading angle calculated by a photoelectric odometer cannot accurately reflect the heading angle of the delivery robot. However, considering that MEMS gyro sensors and magnetic sensors in the IMU are susceptible to zero-point drift, white noise, temperature, acceleration, integral errors, and changing magnetic fields, the error in the data over a short period of time may be relatively large. If the data in the sampling period interval fluctuates considerably, the change in the heading angle will be significant, and the heading angle for the food delivery robot will not be accurate. Therefore, the heading angle change <inline-formula><mml:math id="mm22"><mml:mrow><mml:mrow><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>&#x003b8;</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> calculated by the photoelectric odometer is still used in the improved odometer positioning method. The formulas of the improved odometer positioning method formulas are as follows, where <inline-formula><mml:math id="mm23"><mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>o</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>X</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm24"><mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>o</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> are the coordinates of the delivery robot [<xref rid="B25-sensors-19-04980" ref-type="bibr">25</xref>].
<disp-formula id="FD11-sensors-19-04980"><label>(11)</label><mml:math id="mm25"><mml:mrow><mml:mrow><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mi>ob</mml:mi></mml:mrow></mml:msub><mml:mo>&#x000d7;</mml:mo><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>t</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mi>cos</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>&#x003b1;</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD12-sensors-19-04980"><label>(12)</label><mml:math id="mm26"><mml:mrow><mml:mrow><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mi>ob</mml:mi></mml:mrow></mml:msub><mml:mo>&#x000d7;</mml:mo><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>t</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mi>sin</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>&#x003b1;</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD13-sensors-19-04980"><label>(13)</label><mml:math id="mm27"><mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>o</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:mi>L</mml:mi><mml:mi>o</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>X</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>X</mml:mi></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD14-sensors-19-04980"><label>(14)</label><mml:math id="mm28"><mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>o</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:mi>L</mml:mi><mml:mi>o</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>Y</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>The simulation experiment assumes that the delivery robot moves from the origin in the two-dimensional <italic>X</italic>-<italic>Y</italic> coordinate system, i.e., (0,0) by 25 m along the <italic>X</italic>-axis direction. The initial direction of the IMU is 0&#x000b0;, and its noise is assumed to be Gaussian white noise. Factors such as magnetic field interference in the environment are not considered temporarily. <xref ref-type="fig" rid="sensors-19-04980-f004">Figure 4</xref> shows a simulation diagram of the delivery robot motion trajectories obtained by the traditional odometer positioning method and the improved odometer positioning method in the two-dimensional plane.</p><p>The coordinates calculated by both the traditional odometer positioning method and the improved odometer positioning method include errors. However, the error in the latter is obviously smaller than that in the former. The error is mainly caused by the heading angle change within the sampling period. It is analyzed as follows.</p><p>Assume that the sampling interval of the master control system is <inline-formula><mml:math id="mm29"><mml:mrow><mml:mrow><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>, the distance traveled by the delivery robot is <inline-formula><mml:math id="mm30"><mml:mrow><mml:mrow><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>S</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mi>o</mml:mi><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mo>&#x000d7;</mml:mo><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>, and the change in the heading angle is <inline-formula><mml:math id="mm31"><mml:mrow><mml:mrow><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>&#x003b8;</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>. If the delivery robot moves from the origin <inline-formula><mml:math id="mm32"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> by 1 m to the coordinate point <inline-formula><mml:math id="mm33"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, the theoretical displacement <inline-formula><mml:math id="mm34"><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:math></inline-formula> is 1 m and the actual displacement <inline-formula><mml:math id="mm35"><mml:mrow><mml:mrow><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>S</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> is <inline-formula><mml:math id="mm36"><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> m. The theoretical heading angle variation is 0&#x000b0; and the actual heading angle variation <inline-formula><mml:math id="mm37"><mml:mrow><mml:mrow><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>&#x003b8;</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> is <inline-formula><mml:math id="mm38"><mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>&#x000b0;, where <inline-formula><mml:math id="mm39"><mml:mrow><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm40"><mml:mrow><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>&#x003b8;</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> are the errors in the distance and heading angle variation, respectively.</p><p>Thus, we have
<disp-formula id="FD15-sensors-19-04980"><label>(15)</label><mml:math id="mm41"><mml:mrow><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mi>o</mml:mi><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mo>&#x000d7;</mml:mo><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>t</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mi>cos</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>&#x003b8;</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mi>&#x003b8;</mml:mi><mml:mn>2</mml:mn></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>S</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mi>cos</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>&#x003b8;</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>cos</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mn>0</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mi>&#x003b8;</mml:mi></mml:msub></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mi>o</mml:mi><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mo>&#x000d7;</mml:mo><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>t</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mi>sin</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>&#x003b8;</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mi>&#x003b8;</mml:mi><mml:mn>2</mml:mn></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>S</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mi>sin</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>&#x003b8;</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>sin</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mn>0</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mi>&#x003b8;</mml:mi></mml:msub></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>For example, suppose that <inline-formula><mml:math id="mm42"><mml:mrow><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is 0.001 m and <inline-formula><mml:math id="mm43"><mml:mrow><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>&#x003b8;</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is 0&#x000b0;. Then, <inline-formula><mml:math id="mm44"><mml:mrow><mml:mrow><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm45"><mml:mrow><mml:mrow><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> are given by
<disp-formula id="FD16-sensors-19-04980"><mml:math id="mm46"><mml:mrow><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1.001</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x000d7;</mml:mo><mml:mi>cos</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1.001</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1.001</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x000d7;</mml:mo><mml:mi>sin</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>It can be seen that <inline-formula><mml:math id="mm47"><mml:mrow><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> affects only the direction of the movement of the robot.</p><p>If we assume that <inline-formula><mml:math id="mm48"><mml:mrow><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mi>m</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm49"><mml:mrow><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>&#x003b8;</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mn>2</mml:mn><mml:mo>&#x02218;</mml:mo></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>, then <inline-formula><mml:math id="mm50"><mml:mrow><mml:mrow><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm51"><mml:mrow><mml:mrow><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> are given by
<disp-formula id="FD17-sensors-19-04980"><mml:math id="mm52"><mml:mrow><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:mi>cos</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02248;</mml:mo><mml:mn>0.998</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mi>sin</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02248;</mml:mo><mml:mn>0.0175</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>It can be seen that <inline-formula><mml:math id="mm53"><mml:mrow><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>&#x003b8;</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> affects both the <italic>X</italic>-axis and the <italic>Y</italic>-axis values. With time, the error along the two axes will be introduced once in each interval <inline-formula><mml:math id="mm54"><mml:mrow><mml:mrow><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>, which will contribute to the cumulative error of the final positioning result. Thus, the cumulative error will increase with time. The longer the running time and the longer the operating distance, the larger is the error in the positioning coordinates.</p><p>The traditional odometer positioning method has high accuracy and good stability for a short duration and short distance. However, for a long duration and long distance, it cannot accurately reflect the coordinates of the delivery robot. The improved odometer positioning method based on the IMU is less stable than the traditional odometer positioning method, but it can reflect the coordinates of the delivery robot accurately over a long duration and long distance.</p></sec><sec id="sec2dot3-sensors-19-04980"><title>2.3. UWB Positioning Method</title><p>As shown in <xref ref-type="fig" rid="sensors-19-04980-f004">Figure 4</xref>, the UWB positioning system builds a reference on the basis of the fixed reference nodes in the four corners of the room (anchors) and a mobile node (node labels) mounted on the robot. UWB communication between the mobile node and the fixed nodes is achieved via wireless data transmission [<xref rid="B17-sensors-19-04980" ref-type="bibr">17</xref>]. The UWB positioning algorithm is implemented by the embedded firmware.</p><p>The fixed nodes are installed on the ceiling of the dining room to reduce isolation. The bi-directional ranging method is used to convert the distance <inline-formula><mml:math id="mm55"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>l</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>l</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>l</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> between the fixed nodes and the mobile node into a two-dimensional distance <inline-formula><mml:math id="mm56"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Then, the trilateral positioning algorithm is used to calculate the robot location coordinates [<xref rid="B9-sensors-19-04980" ref-type="bibr">9</xref>].</p><p><xref ref-type="fig" rid="sensors-19-04980-f005">Figure 5</xref> shows three known points (fixed points) <italic>A</italic><inline-formula><mml:math id="mm57"><mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, <italic>B</italic><inline-formula><mml:math id="mm58"><mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, and <italic>C</italic><inline-formula><mml:math id="mm59"><mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, an unknown point (mobile point) <inline-formula><mml:math id="mm60"><mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, and distances <inline-formula><mml:math id="mm61"><mml:mrow><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="mm62"><mml:mrow><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="mm63"><mml:mrow><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> from point <italic>X</italic> to points <italic>A</italic>, <italic>B</italic>, and <italic>C</italic>. Considering three circles with radii of <inline-formula><mml:math id="mm64"><mml:mrow><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="mm65"><mml:mrow><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="mm66"><mml:mrow><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, the coordinates of the unknown point <italic>X</italic> are obtained according to the Pythagorean theorem.</p><p>The unknown point is calculated as follows:<disp-formula id="FD18-sensors-19-04980"><label>(16)</label><mml:math id="mm67"><mml:mrow><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>When <inline-formula><mml:math id="mm68"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02260;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, the solution of be obtained as
<disp-formula id="FD19-sensors-19-04980"><label>(17)</label><mml:math id="mm69"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mfrac><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mi>C</mml:mi></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mi>C</mml:mi></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mfrac><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mi>C</mml:mi></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mi>C</mml:mi></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm70"><mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>,
<disp-formula id="FD20-sensors-19-04980"><mml:math id="mm71"><mml:mrow><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>&#x02212;</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mn>3</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>&#x02212;</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:mn>3</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>&#x02212;</mml:mo><mml:msubsup><mml:mi>d</mml:mi><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>d</mml:mi><mml:mn>3</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD21-sensors-19-04980"><mml:math id="mm72"><mml:mrow><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>&#x02212;</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mn>3</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>&#x02212;</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:mn>3</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>&#x02212;</mml:mo><mml:msubsup><mml:mi>d</mml:mi><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>d</mml:mi><mml:mn>3</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>The accuracy of the UWB positioning system does not decrease with time, as it does not include accumulated errors. However, the system is affected by external interference. Hence, we use a fusion algorithm for the fusion of odometer data and location data with the UWB positioning system to ensure the accuracy of the coordinates in real time.</p></sec><sec id="sec2dot4-sensors-19-04980"><title>2.4. Fusion of UWB and Odometer Information by Kalman Filtering</title><p>As the layout of most restaurants consists of tables and chairs in fixed positions with corridors between them, we set the moving routine of the meal delivery robot according to such a restaurant layout. The robot path width is determined by the width and positioning error of the robot. In this case, the path width is greater than of the robot and includes an error band.</p><p>Compared with the odometer location method, the positioning error of the UWB positioning system does not increase with time. There is no accumulated error, but there are some random errors [<xref rid="B9-sensors-19-04980" ref-type="bibr">9</xref>]. The fusion algorithm can fuse two positioning methods to exploit the advantages of both. Thus, it can guarantee positioning precision and improve system stability. The proposed fusion algorithm introduces a combined navigation technology based on a Kalman filter, i.e., it combines the odometer location method with ultra-wide band navigation technology through an optimal linear estimation algorithm. In other words, it mutually corrects these complementary technologies. Specifically, it ensures not only timely correction of the odometer location coordinates by addressing the coordinate drift but also effective modification of the ultra-wide band positioning by addressing the random errors and faults. Thus, the dynamic stability and accuracy of the system are improved considerably [<xref rid="B14-sensors-19-04980" ref-type="bibr">14</xref>].</p><p>Considering that the electronic compass can measure the accuracy of the heading to meet the navigation requirements, using the Kalman filter for the integrated navigation system operation [<xref rid="B12-sensors-19-04980" ref-type="bibr">12</xref>] involves only one displacement:<disp-formula id="FD22-sensors-19-04980"><label>(18)</label><mml:math id="mm73"><mml:mrow><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi>cos</mml:mi><mml:msub><mml:mi>&#x003b8;</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="script">&#x00393;</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>y</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi>sin</mml:mi><mml:msub><mml:mi>&#x003b8;</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="script">&#x00393;</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Furthermore,
<disp-formula id="FD23-sensors-19-04980"><label>(19)</label><mml:math id="mm74"><mml:mrow><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>As the intervals between the samples are small, <inline-formula><mml:math id="mm75"><mml:mrow><mml:mrow><mml:msub><mml:mi>&#x003b8;</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>&#x02248;</mml:mo><mml:msub><mml:mi>&#x003b8;</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, where <italic>&#x003b8;</italic> represents the steering angle at time <italic>k</italic> &#x02212; 1 and <italic>k</italic>.</p><p>Here, <inline-formula><mml:math id="mm76"><mml:mrow><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> represent the projection process noise sequences, <inline-formula><mml:math id="mm77"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="script">&#x00393;</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="script">&#x00393;</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> are the noise input coefficients, <inline-formula><mml:math id="mm78"><mml:mrow><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="mm79"><mml:mrow><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> are the robot positioning coordinates calculated by the UWB positioning system, and <inline-formula><mml:math id="mm80"><mml:mrow><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> represent the equivalent noise sequences of the UWB measurement system.</p><p>According to the work environment, the process noise sequences and observation noise sequences can be set as random constant-mean Gaussian white noise sequences. Then, we establish a process noise covariance <inline-formula><mml:math id="mm81"><mml:mrow><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and system noise (measured noise of UWB positioning system) variance <inline-formula><mml:math id="mm82"><mml:mrow><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>. Throughout the filtering process, the system processes are not related to the noise or noise sequences, i.e., the initial state <inline-formula><mml:math id="mm83"><mml:mrow><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> of the system is not related to the noise or noise sequences. The initial state of the robot positioning coordinates, <inline-formula><mml:math id="mm84"><mml:mrow><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, and the initial filtering error value <inline-formula><mml:math id="mm85"><mml:mrow><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> are known [<xref rid="B19-sensors-19-04980" ref-type="bibr">19</xref>].</p><p>Based on the Kalman filter procedure, the odometer navigation system and UWB navigation system undergo the following filter estimation process [<xref rid="B14-sensors-19-04980" ref-type="bibr">14</xref>]:
<list list-type="simple"><list-item><label>(1)</label><p>State prediction
<disp-formula id="FD24-sensors-19-04980"><label>(20)</label><mml:math id="mm86"><mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msub><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mover><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msub><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mover><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mi>cos</mml:mi><mml:msub><mml:mi>&#x003b8;</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>sin</mml:mi><mml:msub><mml:mi>&#x003b8;</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p></list-item><list-item><label>(2)</label><p>State estimation
<disp-formula id="FD25-sensors-19-04980"><label>(21)</label><mml:math id="mm87"><mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msub><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>k</mml:mi></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mover><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>k</mml:mi></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msub><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mover><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="normal">z</mml:mi><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="normal">z</mml:mi><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p></list-item><list-item><label>(3)</label><p>Filter gain
<disp-formula id="FD26-sensors-19-04980"><label>(22)</label><mml:math id="mm88"><mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mfrac bevelled="true"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mfrac bevelled="true"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p></list-item><list-item><label>(4)</label><p>Step error
<disp-formula id="FD27-sensors-19-04980"><label>(23)</label><mml:math id="mm89"><mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msup><mml:mi mathvariant="script">&#x00393;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:msub><mml:mrow/><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mi mathvariant="script">&#x00393;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:msub><mml:mrow/><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p></list-item><list-item><label>(5)</label><p>Estimation based on error
<disp-formula id="FD28-sensors-19-04980"><label>(24)</label><mml:math id="mm90"><mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msubsup><mml:mi>K</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mi>K</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p></list-item></list></p><p>During this robot localization via fusion, the above-mentioned formula can be obtained using the robot&#x02019;s current position coordinates by selecting the noise variances <inline-formula><mml:math id="mm91"><mml:mrow><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm92"><mml:mrow><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>.</p></sec><sec id="sec2dot5-sensors-19-04980"><title>2.5. Extended Kalman Filter Fusion</title><p>Owing to the presence of external interference and noise, a measurement error exists in the sensor itself as well as in the model. The traditional Kalman filter fusion algorithm introduced above cannot eliminate these errors in practical engineering applications [<xref rid="B26-sensors-19-04980" ref-type="bibr">26</xref>]. Hence, the result will not be the optimal solution. At the same time, only a linear system can use the traditional Kalman filter fusion algorithm, and the noise must be Gaussian white noise. However, this is not straightforward in practical engineering applications. Therefore, we propose an optimized Kalman filter fusion algorithm.</p><p>Among the various non-linear filtering techniques, the EKF fusion algorithm is the simplest algorithm that locally linearizes the Kalman filter fusion algorithm and is suitable for weakly nonlinear [<xref rid="B27-sensors-19-04980" ref-type="bibr">27</xref>,<xref rid="B28-sensors-19-04980" ref-type="bibr">28</xref>], non-Gaussian white noise environments. The EKF fusion algorithm performs a first-order Taylor expansion of the nonlinear function of the system and obtains a linearized system formula to complete the filtering estimation of the target [<xref rid="B29-sensors-19-04980" ref-type="bibr">29</xref>].</p><p>Considering discrete-time nonlinear systems, the state and measurement formula are
<disp-formula id="FD29-sensors-19-04980"><label>(25)</label><mml:math id="mm93"><mml:mrow><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>&#x003c9;</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>&#x003d5;</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>Q</mml:mi></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD30-sensors-19-04980"><label>(26)</label><mml:math id="mm94"><mml:mrow><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>v</mml:mi></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Assuming that the state formula is a linear function and the measurement formula is a nonlinear function, and that the state estimation value <inline-formula><mml:math id="mm95"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>/</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and estimated error covariance matrix <inline-formula><mml:math id="mm96"><mml:mrow><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> at time <inline-formula><mml:math id="mm97"><mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> have been obtained, the steps of the first-order EKF filtering fusion algorithm are as follows.</p><p>According to the known state equation, expand the target state to obtain <inline-formula><mml:math id="mm98"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>/</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>(1) Apply Taylor expansion to the nonlinear measurement formula <inline-formula><mml:math id="mm99"><mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> at <inline-formula><mml:math id="mm100"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="normal">x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>/</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and keep the first item of the formula. Thus, we can obtain
<disp-formula id="FD31-sensors-19-04980"><label>(27)</label><mml:math id="mm101"><mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>/</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02248;</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>/</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mo>&#x02202;</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02202;</mml:mo><mml:msup><mml:mi>h</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mfrac><mml:msub><mml:mo>|</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>/</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>/</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD32-sensors-19-04980"><label>(28)</label><mml:math id="mm102"><mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>/</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>/</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>/</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>/</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm103"><mml:mrow><mml:mrow><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>/</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo>&#x02202;</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02202;</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mfrac><mml:msub><mml:mo>|</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>/</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is the Jacobian matrix of <inline-formula><mml:math id="mm104"><mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>Equation (27) is substituted into Equation (28) to get the approximate linearization model:<disp-formula id="FD33-sensors-19-04980"><label>(29)</label><mml:math id="mm105"><mml:mrow><mml:mrow><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>/</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>/</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>/</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>/</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>v</mml:mi></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>(2) The state filtering update of the gain matrix and error covariance matrix are
<disp-formula id="FD34-sensors-19-04980"><label>(30)</label><mml:math id="mm106"><mml:mrow><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>/</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msup><mml:mi>H</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>H</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>/</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msup><mml:mi>H</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mo>+</mml:mo><mml:mi>R</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD35-sensors-19-04980"><label>(31)</label><mml:math id="mm107"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>/</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>/</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>K</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mi>z</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>/</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD36-sensors-19-04980"><label>(32)</label><mml:math id="mm108"><mml:mrow><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>/</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>I</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>K</mml:mi><mml:mi>H</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>/</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>I</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>K</mml:mi><mml:mi>H</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mo>+</mml:mo><mml:mi>K</mml:mi><mml:mi>R</mml:mi><mml:msup><mml:mi>K</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>As the measurement matrix is replaced by the Jacobian matrix <inline-formula><mml:math id="mm109"><mml:mrow><mml:mi>H</mml:mi></mml:mrow></mml:math></inline-formula>, the gain <inline-formula><mml:math id="mm110"><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:math></inline-formula> calculated from Equation (30) is not the optimal gain. Therefore, the traditional calculation formula for the matrix <italic>P</italic> cannot be used to update the covariance matrix, and Equation (32) must be used to ensure positive-definiteness and symmetry of <italic>P</italic>. This is the only way to prevent the filter from diverging, and it is also the only way to guarantee convergence.</p><p>The accuracy of the EKF fusion algorithm using first-order Taylor expansion depends on the target state dynamic model and the previous state estimation. If <inline-formula><mml:math id="mm111"><mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>/</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is sufficiently small, the output of the system is the optimal solution.</p><p>The UWB positioning system used in this experiment measures the distance between the reference node and the moving node using the time difference of arrival (TDOA) algorithm and two-way time-of-flight measuring principle. Assuming that the reference node A of the positioning system sends a distance measurement command to the reference node B at time <inline-formula><mml:math id="mm112"><mml:mrow><mml:mrow><mml:msub><mml:mi>&#x003c4;</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>x</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, the reference node B receives the instruction from the reference node A and returns a corresponding response command at time <inline-formula><mml:math id="mm113"><mml:mrow><mml:mrow><mml:msub><mml:mi>&#x003c4;</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>x</mml:mi><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>. The reference node A receives the response command from the reference node B at the <inline-formula><mml:math id="mm114"><mml:mrow><mml:mrow><mml:msub><mml:mi>&#x003c4;</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>x</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and calculates the time difference of the UWB signal from time <inline-formula><mml:math id="mm115"><mml:mrow><mml:mrow><mml:msub><mml:mi>&#x003c4;</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>x</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> to time <inline-formula><mml:math id="mm116"><mml:mrow><mml:mrow><mml:msub><mml:mi>&#x003c4;</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>x</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>. The product of this time difference and the UWB signal speed <inline-formula><mml:math id="mm117"><mml:mrow><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mi>W</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is the distance between the reference node A and the reference node B, <inline-formula><mml:math id="mm118"><mml:mrow><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>. Hence, the formula for obtaining the distance is as follows:<disp-formula id="FD37-sensors-19-04980"><label>(33)</label><mml:math id="mm119"><mml:mrow><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mi>W</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>&#x000d7;</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>&#x003c4;</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>x</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>&#x003c4;</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>x</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>&#x003c4;</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>x</mml:mi><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>&#x003c4;</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>x</mml:mi><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>In the line-of-sight (LOS) environment, <inline-formula><mml:math id="mm120"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>d</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is assumed as the measured distance between reference point <inline-formula><mml:math id="mm121"><mml:mrow><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and reference point <inline-formula><mml:math id="mm122"><mml:mrow><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>. Then, the true value of the distance is
<disp-formula id="FD38-sensors-19-04980"><label>(34)</label><mml:math id="mm123"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>d</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm124"><mml:mrow><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is an absolute error function. This function is related to the actual distance. According to the actual application of the delivery robot, this study assumes that this function is a linear function.
<disp-formula id="FD39-sensors-19-04980"><label>(35)</label><mml:math id="mm125"><mml:mrow><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mi>d</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD40-sensors-19-04980"><label>(36)</label><mml:math id="mm126"><mml:mrow><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>d</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>/</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>In practice, there are many obstacles in the working environment of the delivery robot. The environment must be a non-line-of-sight (NLOS) environment. NLOS errors will cause interference, diffraction, and other phenomena that affect the UWB signal. Hence, there are errors in the time difference between reference nodes receiving the signal. Therefore, we assume that the indoor environment of the experimental platform does not change and that the obstacles in the environment are all of the same material so that the NLOS error can be regarded as a fixed constant. Then, the distance formula is rewritten as
<disp-formula id="FD41-sensors-19-04980"><label>(37)</label><mml:math id="mm127"><mml:mrow><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>d</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>&#x02212;</mml:mo><mml:mi>J</mml:mi><mml:mo>&#x022c5;</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mi>L</mml:mi><mml:mi>O</mml:mi><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mi>S</mml:mi><mml:mi>N</mml:mi><mml:mi>R</mml:mi><mml:mo>&#x02265;</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mi>N</mml:mi><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>J</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>S</mml:mi><mml:mi>N</mml:mi><mml:mi>R</mml:mi><mml:mo>&#x02264;</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mi>N</mml:mi><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>J</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm128"><mml:mrow><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mi>L</mml:mi><mml:mi>O</mml:mi><mml:mi>S</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is the <italic>NLOS</italic> error constant in the indoor environment. The signal-to-noise ratio (SNR) is the ratio between the signal received by the mobile nodes and the system noise, while <inline-formula><mml:math id="mm129"><mml:mrow><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mi>N</mml:mi><mml:mi>R</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is the ranging condition determination threshold. The UWB positioning system used in this experiment employs the TDOA positioning algorithm. To ensure accurate calculation of the arrival time difference, the algorithm must ensure that the reference nodes of the UWB positioning system are at the same height. As shown in <xref ref-type="fig" rid="sensors-19-04980-f006">Figure 6</xref>, reference node A is the origin of the coordinate system, the line connecting reference node B and reference node C is the <italic>X</italic>-axis, and the line connecting reference node A and reference node C is the <italic>Y</italic>-axis. The <italic>Z</italic>-axis direction is perpendicular to the horizontal plane formed by the reference nodes A, B, and C.</p><p>From <xref ref-type="fig" rid="sensors-19-04980-f006">Figure 6</xref>, we can see that the position of the intersection of the three circles is the position of the mobile node D. Assuming the coordinates as <inline-formula><mml:math id="mm130"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, the coordinates of the reference nodes A, B, and C are <inline-formula><mml:math id="mm131"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="mm132"><mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>. According to the Euclidean distance formula, the distance between the mobile node and the reference node is calculated as
<disp-formula id="FD42-sensors-19-04980"><label>(38)</label><mml:math id="mm133"><mml:mrow><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msqrt></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>According to Equation (33), the coordinates of the moving node and measured distance are not linearly related. Therefore, the measurement formula is a non-linear equation. Therefore, the EKF fusion algorithm is used to improve positioning accuracy.</p><p>Assume that the state formula of the system&#x02019;s reference node A is
<disp-formula id="FD43-sensors-19-04980"><label>(39)</label><mml:math id="mm134"><mml:mrow><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>~</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>The nonlinear measurement formula is
<disp-formula id="FD44-sensors-19-04980"><label>(40)</label><mml:math id="mm135"><mml:mrow><mml:mrow><mml:msub><mml:mi>Z</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>~</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm136"><mml:mrow><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is the velocity vector of the moving node relative to the coordinate system. This vector orthogonally decomposes the corresponding velocity and corresponding coordinates of the <inline-formula><mml:math id="mm137"><mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mi>Z</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> axes.
<disp-formula id="FD45-sensors-19-04980"><label>(41)</label><mml:math id="mm138"><mml:mrow><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi>z</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD46-sensors-19-04980"><label>(42)</label><mml:math id="mm139"><mml:mrow><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:mfrac><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>z</mml:mi></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>In Equation (39), <inline-formula><mml:math id="mm140"><mml:mrow><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is the covariance matrix of the prediction noise vector <inline-formula><mml:math id="mm141"><mml:mrow><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="mm142"><mml:mrow><mml:mrow><mml:msub><mml:mi>Z</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is the measurement distance vector between the reference nodes and the moving node, which is concretely expressed as
<disp-formula id="FD47-sensors-19-04980"><label>(43)</label><mml:math id="mm143"><mml:mrow><mml:mrow><mml:msub><mml:mi>Z</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm144"><mml:mrow><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is the covariance matrix of the noise vector <inline-formula><mml:math id="mm145"><mml:mrow><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm146"><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:math></inline-formula> is the sampling period of the system. Then, the equations of the EKF fusion algorithm are as follows:<disp-formula id="FD48-sensors-19-04980"><label>(44)</label><mml:math id="mm147"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>k</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD49-sensors-19-04980"><label>(45)</label><mml:math id="mm148"><mml:mrow><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mover accent="true"><mml:mi>k</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>&#x003c6;</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>&#x003c6;</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD50-sensors-19-04980"><label>(46)</label><mml:math id="mm149"><mml:mrow><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mover accent="true"><mml:mi>k</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover></mml:msub><mml:msubsup><mml:mi>H</mml:mi><mml:mi>k</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>H</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:msub><mml:mi>P</mml:mi><mml:mover accent="true"><mml:mi>k</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover></mml:msub><mml:msubsup><mml:mi>H</mml:mi><mml:mi>k</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD51-sensors-19-04980"><label>(47)</label><mml:math id="mm150"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>k</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>K</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>Z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>k</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>k</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD52-sensors-19-04980"><label>(48)</label><mml:math id="mm151"><mml:mrow><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>I</mml:mi><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:msub><mml:mi>H</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mover accent="true"><mml:mi>k</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm152"><mml:mrow><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is the gain calculation matrix of the EKF fusion algorithm, <inline-formula><mml:math id="mm153"><mml:mrow><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is the system error&#x02019;s covariance matrix, and <inline-formula><mml:math id="mm154"><mml:mrow><mml:mrow><mml:msub><mml:mi>&#x003c6;</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>&#x02248;</mml:mo><mml:mfrac><mml:mrow><mml:mo>&#x02202;</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo>&#x02202;</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:mfrac><mml:mo>|</mml:mo><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mover accent="true"><mml:mi>k</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is a system state transition matrix. Further, <inline-formula><mml:math id="mm155"><mml:mrow><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msub><mml:mi>I</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mrow><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mi>T</mml:mi><mml:msub><mml:mi>I</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>I</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="mm156"><mml:mrow><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is a third-order identity matrix and <inline-formula><mml:math id="mm157"><mml:mrow><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is the Jacobian matrix of <inline-formula><mml:math id="mm158"><mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> at time <inline-formula><mml:math id="mm159"><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:math></inline-formula>.</p></sec><sec id="sec2dot6-sensors-19-04980"><title>2.6. Meal Delivery Robot Trajectory Control</title><p>To obtain accurate and stable location coordinates, we developed a special trajectory according to the positioning algorithm.</p><p>Considering that the restaurant corridors are often extremely narrow and that the obstacles are usually pedestrians, the robot will stop when it encounters the obstacles and prompt the pedestrians to move. In this case, the infrared and ultrasonic obstacle detection module detects obstacles in front and on the sides.</p><p>The path of the meal delivery robot is set as a fixed path by the embedded software according to the location selected. The robot control processes are shown in <xref ref-type="fig" rid="sensors-19-04980-f007">Figure 7</xref> and the real product is shown in <xref ref-type="fig" rid="sensors-19-04980-f008">Figure 8</xref>. In <xref ref-type="fig" rid="sensors-19-04980-f008">Figure 8</xref>a is the internal structure drawing of robot, <xref ref-type="fig" rid="sensors-19-04980-f008">Figure 8</xref>b is the original food delivery robot, and <xref ref-type="fig" rid="sensors-19-04980-f008">Figure 8</xref>c is the modified product drawing.</p><p>The motion control schedule includes the following steps:<list list-type="simple"><list-item><label>(1)</label><p>According to the restaurant layout, the tables&#x02019; location coordinates and meal delivery robot trajectory coordinates are confirmed.</p></list-item><list-item><label>(2)</label><p>Initially, the odometer heading and attitude sensor data are cleared to ensure that no cumulative error exists.</p></list-item><list-item><label>(3)</label><p>The EKF fusion algorithm is used to get accurate real-time coordinates via the UWB GPS coordinates and odometer.</p></list-item><list-item><label>(4)</label><p>Considering the actual error caused by a &#x0201c;single cumulative error&#x0201d;, the actual driving process adjusts the attitude heading sensor readings in real time to determine the direction of the robot if the error is less than the allowable error [<xref rid="B17-sensors-19-04980" ref-type="bibr">17</xref>].</p></list-item></list></p><p>During the implementation of the fusion algorithm, the system needs to determine whether the UWB positioning system is operating properly by judging the robot movement velocity and displacement. For example, if the robot speed is greater than zero, the displacement of the control cycle is changed. Meanwhile, if the UWB positioning system moves to a certain distance from each reference node, the information on the incremental position and the last position is used for the current real-time location coordinates. If the UWB signal is correct, the odometer positioning result is fused with the UWB localization result using the EKF algorithm to get the current position coordinates in real time [<xref rid="B19-sensors-19-04980" ref-type="bibr">19</xref>].</p><p>During motion, the system error and random errors may cause a shift in the trajectory of the robot. Hence, adjustment is required. Within the predetermined track range, the running attitude is maintained. Outside the predetermined track range, the running attitude is adjusted. The adjustment method is as follows. If the robot moves to the left (right) beyond the predetermined trajectory, the left (right) wheel speed will be increased. Using the fuzzy logic control strategy, the system achieves real-time online fuzzy control in the case of the speed difference between the left and right wheels [<xref rid="B18-sensors-19-04980" ref-type="bibr">18</xref>].</p></sec></sec><sec id="sec3-sensors-19-04980"><title>3. Experiment and Result Analysis</title><sec id="sec3dot1-sensors-19-04980"><title>3.1. Experimental System</title><p>We design a comparative experiment as follows. We use the ROS platform as a control platform to control the delivery robot motion along the reference trajectory, and we obtain the coordinates of the UWB positioning system as well as those of the improved odometer positioning method. When the improved odometer positioning method is used, the heading angle of the robot must be calculated and measured by the IMU. After obtaining two sets of coordinates, the EKF fusion algorithm is used to fuse the data in order to verify the optimization of accuracy and stability. The diameter of the drive wheel of the delivery robot is 12 cm, and the distance between the left and right wheels is 34 cm.</p><p><xref ref-type="fig" rid="sensors-19-04980-f009">Figure 9</xref> shows a schematic diagram of the operation site. The experimental environment is a square room with a side length of 15 m. The environment has no special requirements, so there is no detailed description. Although the robot has the infrared and ultrasonic obstacle detection module, the obstacle avoidance function is not included in the study. In addition, the obstacles are usually pedestrians. There is no barrier in the experiment room except for some tables and chairs. The operators are in the room but not on the robot&#x02019;s trajectory and they may affect UWB signal reception. The environment was similar to that of a restaurant. The reference nodes of the UWB positioning system are respectively placed at the four vertices of the square region, and the <italic>x</italic>-<italic>y</italic> two-dimensional coordinate system is established with reference node 1 as the origin. The remote control delivery robot starts from the point <inline-formula><mml:math id="mm160"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and finally returns to this starting point via the points <inline-formula><mml:math id="mm161"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>12</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="mm162"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>12</mml:mn><mml:mo>,</mml:mo><mml:mn>12</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="mm163"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>12</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. The walking trajectory is the edge of a square whose side is 9 m long.</p><p>During the experiment, the data sampling frequencies of the UWB positioning system, IMU, and odometer are all 10 Hz.</p></sec><sec id="sec3dot2-sensors-19-04980"><title>3.2. UWB Positioning System Position</title><p>The mobile node of the UWB positioning system is installed on the head of the robot and the reference nodes are deployed at the four top corners of a square whose side is 15 m long. The installation height of the reference nodes is 2.25 m. The computer software reads the position coordinates of the UWB positioning system using UDP. The control signal is sent to the main control board through the ROS platform in order to control the motor so that the delivery robot runs along the red track in <xref ref-type="fig" rid="sensors-19-04980-f008">Figure 8</xref>. Specifically, the overall verification experiment was conducted by five groups of experiments in two different situations. Situation I is comprised of three groups of experiments and the number of people within the scope of the experimental area is less than four. While situation II is made up of two groups of experiments and there are more than 10 people within the experimental area. In addition, the other obstacles such as tables and chairs are identical in both situations. The track of the delivery robot positioned by the UWB positioning system is shown in <xref ref-type="fig" rid="sensors-19-04980-f010">Figure 10</xref>.</p><p><xref ref-type="fig" rid="sensors-19-04980-f010">Figure 10</xref>a&#x02013;e show the 5 times track of the delivery robot positioned by the ultra-wide band (UWB) positioning system. From <xref ref-type="fig" rid="sensors-19-04980-f010">Figure 10</xref> it can be seen the coordinate data indicates that the accuracy and stability of the positioning coordinates obtained by the UWB positioning system are poor. The main reasons are as follows:<list list-type="simple"><list-item><label>(1)</label><p>Although the TDOA algorithm is used in the UWB positioning system, it is difficult to achieve full synchronization in the initial state owing to the influence of the hardware circuits (mainly, crystal oscillators) and temperature. With time, clock drift will be generated, and the original synchronous clock system becomes unsynchronized. Although the system corrects this error, it still affects the final positioning accuracy.</p></list-item><list-item><label>(2)</label><p>In the UWB signal transmission process, it is difficult to ensure that the environment is completely LOS. The signal will be reflected and refracted owing to obstacles and other factors, and it will become NLOS. This will lead to a reduction in the final positioning accuracy.</p></list-item><list-item><label>(3)</label><p>Because the system in an indoor environment and the moving node is close to the motor power supply, the noise level of the entire system is increased, which reduces the positioning accuracy. At the same time, the randomness of the noise itself may lead to the appearance of some anomalies.</p></list-item></list></p></sec><sec id="sec3dot3-sensors-19-04980"><title>3.3. Coordinate Calculation for Improved Odometer Positioning Method</title><p>When the improved odometer positioning method calculates the coordinates, it needs to use the heading angle calculated by the traditional odometer positioning method and the heading angle measured by the IMU as the input. Therefore, the heading angle is first calculated to obtain two sets of heading angles. Then, the coordinates are calculated.</p><p>(1) IMU heading angle measurement</p><p>The heading angle was measured by the IMU and five sets of experimental data were obtained. One set of heading angle changes as shown in <xref ref-type="fig" rid="sensors-19-04980-f011">Figure 11</xref>.</p><p>In <xref ref-type="fig" rid="sensors-19-04980-f011">Figure 11</xref>, the first stage is the start-up operation stage. At this time, the delivery robot started and moved to the first 90&#x000b0; turning point. In this process, the theoretical heading angle measured by the IMU is 0&#x000b0;.</p><p>In the second stage, the delivery robot rotated through 90&#x000b0;, and the theoretical heading angle after turning was &#x02212;90&#x000b0;. Then, the robot moved in a straight direction again, reached the second turning point, and rotated through 90&#x000b0;. At this time, the theoretical heading angle should be 180&#x000b0;. The measurement data of the IMU has errors, and the theoretical range of its measurement values is (&#x02212;180&#x000b0;, 180&#x000b0;]. Hence, measurement data similar to the step signal will be generated at a specific time. The delivery robot will then return to the starting point via the remaining turning points and the straight path. <xref ref-type="fig" rid="sensors-19-04980-f012">Figure 12</xref> shows the rest 4 sets of heading angles measured by the IMU.</p><p>The main error of the IMU comes from the following sources.
<list list-type="simple"><list-item><label>(i)</label><p>Vibration caused by the motion of the delivery robot: When the accelerometer works with the vibration interference, its measurement error will become larger.</p></list-item><list-item><label>(ii)</label><p>Electromagnetic and metal interferences during the operation of the robot: Although the IMU has a filtering algorithm to filter the electromagnetic interference, the distance between the servo motor and the sensor is fairly short, which affects the measurement precision of the IMU. In addition, the IMU has been calibrated to be insensitive to the metal material of the delivery robot, errors may still be induced during the motion of the robot.</p></list-item><list-item><label>(iii)</label><p>The gyroscope in the IMU will have zero drift, which means that even with a heading angle of 0&#x000b0;, the unit will have an output. At the same time, the measurement unit&#x02019;s data will be affected by the temperature.</p></list-item></list></p><p>(2) Traditional odometer positioning method heading angle measurement</p><p>When the traditional odometer positioning method calculates the heading angle, the time interval between the initial time t0 and t1 is set as the sampling period, which is 100 ms. The odometer data QCL and QCR of the left and right wheels are sampled every 100 ms.</p><p>The traditional odometer positioning method was used in five groups of experiments to calculate the heading angle. <xref ref-type="fig" rid="sensors-19-04980-f013">Figure 13</xref> shows the calculated heading angle data of 5 experiments.</p><p>As can be seen from <xref ref-type="fig" rid="sensors-19-04980-f013">Figure 13</xref>, the heading angle calculated by the odometer data is highly accurate in the beginning, but the error increases with the distance owing to the accumulated error.</p><p>The final cumulative error comes from two sources. The first one is the floating-point error that is generated when calculating the heading angle from the formula. Considering the computing power of the main control chip, only two decimal places are reserved for each calculation of the heading angle. The heading angle is also obtained by accumulating the heading angle variations <inline-formula><mml:math id="mm164"><mml:mrow><mml:mrow><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>&#x003b8;</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> during the sampling period <inline-formula><mml:math id="mm165"><mml:mrow><mml:mrow><mml:mi mathvariant="script">&#x00394;</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>, which will lead to greater errors. The second source is the accuracy error of the odometer itself and the measurement error during the experiment.</p></sec><sec id="sec3dot4-sensors-19-04980"><title>3.4. Positioning Coordinate Calculation</title><p>The heading angle measured by the IMU and the heading angle calculated by the odometer data in the sampling period were used as the input parameters of the improved odometer positioning method to calculate the coordinates. The experiments were performed five times. <xref ref-type="fig" rid="sensors-19-04980-f014">Figure 14</xref> shows the coordinate data obtained by the improved odometer positioning method.</p><p>From <xref ref-type="fig" rid="sensors-19-04980-f014">Figure 14</xref>, the heading angles measured by IMU and by the odometer data are used to calculate the coordinates of the robot, the connection part of the coordinate image is not a straight line. This is because the heading angle measured by the IMU changes under the influence of the error. Considering that the IMU is sensitive to magnetic fields and metals, the data will still fluctuate when these two interference sources are suddenly encountered. Possible sources of interference are metal shelves, elevators, etc. The stability of the IMU is poor, and it is easily affected by environmental factors. The heading angle measured by the IMU will affect the final positioning coordinate data of the improved odometer positioning method.</p><p>The improved odometer positioning method combines the IMU, which can accurately reflect the heading angle, and the odometer, which calculates the heading angle with a small error. It can obtain better coordinates in the case of long-duration and long-distance operation. However, the IMU data are susceptible to interference and large fluctuations. Hence, the independent use of the improved odometer positioning method is not reliable.</p></sec><sec id="sec3dot5-sensors-19-04980"><title>3.5. EKF Fusion Algorithm Coordinate Fusion Experiment</title><p>In this experiment, the positioning results of the UWB positioning system are fused with those of the improved odometer positioning method to obtain the positioning results with better accuracy and stability, closer to the actual situation. The positioning results of the improved odometer positioning method are used as the observations of the EKF algorithm, and the positioning results of the UWB positioning system are used as the state variables of the EKF algorithm. We set the initial parameters and status of the system as follows: system noise Q = 0.4, the variance of the measurement noise of the UWB positioning system R = 0.35. The sampling frequency of both methods is 10 Hz. After the EKF fusion algorithm is executed, the fusion coordinates are obtained. <xref ref-type="fig" rid="sensors-19-04980-f015">Figure 15</xref> compares the EKF fusion coordinates with the original coordinates.</p><p>From <xref ref-type="fig" rid="sensors-19-04980-f015">Figure 15</xref>, it can be clearly seen that the accuracy and stability of the fusion positioning results have improved. According to the positioning error calculation formula, the distance of the actual positioning coordinates from the ideal coordinates can be calculated. This distance value reflects the positioning accuracy. The error calculation formula is as follows:<disp-formula id="FD53-sensors-19-04980"><label>(49)</label><mml:math id="mm166"><mml:mrow><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mi>X</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mi>Y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msqrt></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm167"><mml:mrow><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is the distance of the measured coordinates or fused coordinates from the ideal coordinates, <inline-formula><mml:math id="mm168"><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm169"><mml:mrow><mml:mi>Y</mml:mi></mml:mrow></mml:math></inline-formula> are the horizontal and vertical values of the ideal coordinates, and <inline-formula><mml:math id="mm170"><mml:mrow><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm171"><mml:mrow><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> are the horizontal and vertical values of the measured or fused coordinates.</p><p><xref ref-type="fig" rid="sensors-19-04980-f016">Figure 16</xref> shows the 5 experiments&#x02019; error comparison of the coordinates of the UWB positioning system, the improved odometer positioning method, and the EKF fusion algorithm. To be more intuitively, the statistical results of the maximum position errors of the three positioning methods are listed in <xref rid="sensors-19-04980-t001" ref-type="table">Table 1</xref>.</p><p>From <xref rid="sensors-19-04980-t001" ref-type="table">Table 1</xref>, it can be seen that the position error of the EKF fusion algorithm is far less than using the IMU or UWB. In addition, the number of indoor people has little effect on the accuracy of the UWB and IMU integrated system. On the other hand, the accuracy of UWB alone is sensitive to the number of people in the room. As the number of people in the room increases, the accuracy of using UWB alone will be decreased. This also verified the effect of the human body on the UWB signal reception. From the table, it can also be seen that the number of people has little effect on the IMU, which is consistent with the characteristics of the IMU.</p><p>The following conclusions can be drawn from the coordinate comparison and error comparison. The UWB positioning system has poor positioning stability and low positioning accuracy. Especially when the number of indoor people or things increases, the accuracy is further reduced. When it is used independently, it is difficult to provide reliable coordinate data for the delivery robot. The improved odometer positioning method has better positioning results, and the error of the start-up phase of the delivery robot is also smaller. However, with time, the cumulative error increases. Thus, the final positioning accuracy decreases. The stability and accuracy of the positioning coordinates after fusion by the EKF fusion algorithm are improved considerably compared to the independent use of the first two methods. In particular, the positioning error of the fused coordinates is less than 15 cm.</p><p>This experiment verified the effect of the EKF fusion algorithm on the positioning results. However, considering the poor positioning stability of the UWB positioning system and the accumulated error of the improved odometer positioning method, the final error of the fused positioning coordinates is still high. Therefore, although the fused positioning results have been improved compared to the use of a single positioning method, there is scope for further optimization.</p></sec></sec><sec sec-type="conclusions" id="sec4-sensors-19-04980"><title>4. Conclusions</title><p>The growing popularity of robots in the service industry can be attributed to their low labor cost, high efficiency, and attractiveness to customers. Nevertheless, the development and improvement of delivery robots are imperative. In this study, according to the coordinate comparison diagram and error comparison diagram, it can be concluded that the positioning result of the UWB positioning system is of poor stability and low positioning accuracy. When UWB is used independently, it is difficult to provide reliable coordinate data for the food delivery robot. The positioning results of the improved track deduction algorithm are stable and the error of the food robot is small at the beginning of operation. However, with the increase of time, the cumulative error gradually increases and the final positioning accuracy is low. The fusion method of EKF is used to improve the stability and accuracy of the fusion coordinates, and the positioning error is less than 15 cm which can be accepted in a restaurant. Based on this method, the delivery robot has high positioning accuracy, low installation and maintenance costs, wide availability, and low impact on the restaurant layout. Moreover, it is simple and flexible in terms of changing the travel route. Future work will focus on enabling enable multiple delivery robots on site.</p></sec></body><back><notes><title>Author Contributions</title><p>Conceptualization and methodology, Z.C. and Y.G.; software, Y.S. and L.G.; validation, Z.C.; funding, Z.C. and. Y.G.; writing&#x02014;original draft preparation, Y.S. and Z.C.; writing&#x02014;review and editing, L.G. and C.L.</p></notes><notes><title>Funding</title><p>This research work is supported by the Shanghai Sailing Program (19YF1437200, 18YF1418600), the National Natural Science Foundation of China (NSFC) (61803118), the Post Doc. Foundation of Heilongjiang Province (LBH-Z17053) and the Central Universities of China (3072019CF0405).</p></notes><notes notes-type="COI-statement"><title>Conflicts of Interest</title><p>The authors declare no conflict of interest.</p></notes><ref-list><title>References</title><ref id="B1-sensors-19-04980"><label>1.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>L.</given-names></name></person-group><article-title>Application of restaurant service robot</article-title><source>Wind Sci. Technol.</source><year>2015</year><volume>15</volume><fpage>122</fpage><lpage>123</lpage></element-citation></ref><ref id="B2-sensors-19-04980"><label>2.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Wakita</surname><given-names>Y.</given-names></name><name><surname>Tanaka</surname><given-names>H.</given-names></name><name><surname>Matsumoto</surname><given-names>Y.</given-names></name></person-group><article-title>Projection Function and Hand Pointerfor User Interface of Daily Service Robot</article-title><source>Proceedings of the 2017 IEEE International Conference on Robotics and Biomimetics (ROBIO)</source><conf-loc>Macau, China</conf-loc><conf-date>5&#x02013;8 December 2017</conf-date><fpage>2218</fpage><lpage>2224</lpage></element-citation></ref><ref id="B3-sensors-19-04980"><label>3.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Kantharak</surname><given-names>K.</given-names></name><name><surname>Somboonchai</surname><given-names>C.</given-names></name><name><surname>Tuan</surname><given-names>N.T.</given-names></name><name><surname>Thinh</surname><given-names>N.T.</given-names></name></person-group><article-title>Design and development of service robot based human-robot interaction (HRI)</article-title><source>Proceedings of the International Conference on System Science and Engineering</source><conf-loc>Ho Chi Minh City, Vietnam</conf-loc><conf-date>21&#x02013;23 July 2017</conf-date><fpage>293</fpage><lpage>296</lpage></element-citation></ref><ref id="B4-sensors-19-04980"><label>4.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Hernandez-Mendez</surname><given-names>S.</given-names></name><name><surname>Maldonado-Mendez</surname><given-names>C.</given-names></name><name><surname>Marin-Hernandez</surname><given-names>A.</given-names></name><name><surname>Rios-Figueroa</surname><given-names>H.V.</given-names></name></person-group><article-title>Detecting falling people by autonomous service robots: A ROS module integration approach</article-title><source>Proceedings of the International Conference on Electronics, Communications and Computers</source><conf-loc>Cholula, Mexico</conf-loc><conf-date>22&#x02013;24 February 2017</conf-date></element-citation></ref><ref id="B5-sensors-19-04980"><label>5.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shin</surname><given-names>H.</given-names></name><name><surname>Chon</surname><given-names>Y.</given-names></name><name><surname>Kim</surname><given-names>Y.</given-names></name><name><surname>Cha</surname><given-names>H.</given-names></name></person-group><article-title>A participatory service platform for indoor location-based services</article-title><source>IEEE Pervasive Comput.</source><year>2015</year><volume>14</volume><fpage>62</fpage><lpage>69</lpage><pub-id pub-id-type="doi">10.1109/MPRV.2015.1</pub-id></element-citation></ref><ref id="B6-sensors-19-04980"><label>6.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Xin</surname><given-names>J.</given-names></name><name><surname>Jiao</surname><given-names>X.L.</given-names></name><name><surname>Yang</surname><given-names>Y.</given-names></name><name><surname>Liu</surname><given-names>D.</given-names></name></person-group><article-title>Visual navigation for mobile robot with Kinect camera in dynamic environment</article-title><source>Proceedings of the Chinese Control Conference</source><conf-loc>Chengdu, China</conf-loc><conf-date>27&#x02013;29 July 2016</conf-date><fpage>4757</fpage><lpage>4764</lpage></element-citation></ref><ref id="B7-sensors-19-04980"><label>7.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Gulalkari</surname><given-names>A.V.</given-names></name><name><surname>Sheng</surname><given-names>D.</given-names></name><name><surname>Pratama</surname><given-names>P.S.</given-names></name><name><surname>Kim</surname><given-names>H.K.</given-names></name><name><surname>Byun</surname><given-names>G.S.</given-names></name><name><surname>Kim</surname><given-names>S.B.</given-names></name></person-group><article-title>Kinect camera sensor-based object tracking and following of four wheel independent steering automatic guided vehicle using Kalman filter</article-title><source>Proceedings of the International Conference on Control, Automation and Systems</source><conf-loc>Busan, Korea</conf-loc><conf-date>13&#x02013;16 October 2015</conf-date><fpage>1650</fpage><lpage>1655</lpage></element-citation></ref><ref id="B8-sensors-19-04980"><label>8.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haiyu</surname><given-names>L.</given-names></name><name><surname>You</surname><given-names>L.</given-names></name><name><surname>Naser</surname><given-names>E.S.</given-names></name></person-group><article-title>Pdr/ins/wifi integration based on handheld devices for indoor pedestrian navigation</article-title><source>Micromachines</source><year>2015</year><volume>6</volume><fpage>793</fpage><lpage>812</lpage></element-citation></ref><ref id="B9-sensors-19-04980"><label>9.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Woods</surname><given-names>J.O.</given-names></name><name><surname>Christian</surname><given-names>J.A.</given-names></name></person-group><article-title>Lidar-based relative navigation with respect to non-cooperative objects</article-title><source>Acta Astronaut.</source><year>2016</year><volume>126</volume><fpage>298</fpage><lpage>311</lpage><pub-id pub-id-type="doi">10.1016/j.actaastro.2016.05.007</pub-id></element-citation></ref><ref id="B10-sensors-19-04980"><label>10.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Xujian</surname><given-names>H.</given-names></name><name><surname>Hao</surname><given-names>W.</given-names></name></person-group><article-title>WIFI indoor positioning algorithm based on improved Kalman filtering</article-title><source>Proceedings of the International Conference on Intelligent Transportation, Big Data &#x00026; Smart City (ICITBS)</source><conf-loc>Changsha, China</conf-loc><conf-date>17&#x02013;18 December 2016</conf-date><fpage>349</fpage><lpage>352</lpage></element-citation></ref><ref id="B11-sensors-19-04980"><label>11.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>W.</given-names></name><name><surname>Hua</surname><given-names>X.</given-names></name><name><surname>Yu</surname><given-names>K.</given-names></name><name><surname>Qiu</surname><given-names>W.</given-names></name><name><surname>Zhang</surname><given-names>S.</given-names></name></person-group><article-title>Domain clustering based WiFi indoor positioning algorithm</article-title><source>Proceedings of the International Conference on Indoor Positioning and Indoor Navigation (IPIN)</source><conf-loc>Alcala de Henares, Spain</conf-loc><conf-date>4&#x02013;7 October 2016</conf-date><fpage>1</fpage><lpage>5</lpage></element-citation></ref><ref id="B12-sensors-19-04980"><label>12.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>K.</given-names></name><name><surname>Wen</surname><given-names>K.</given-names></name><name><surname>Li</surname><given-names>Y.</given-names></name><name><surname>Zhang</surname><given-names>S.</given-names></name><name><surname>Zhang</surname><given-names>K.</given-names></name></person-group><article-title>A Novel NLOS Mitigation Algorithm for UWB Localization in Harsh Indoor Environments</article-title><source>IEEE Trans. Veh. Technol.</source><year>2018</year><volume>68</volume><fpage>686</fpage><lpage>699</lpage><pub-id pub-id-type="doi">10.1109/TVT.2018.2883810</pub-id></element-citation></ref><ref id="B13-sensors-19-04980"><label>13.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rahman</surname><given-names>M.A.</given-names></name><name><surname>Reaz</surname><given-names>M.B.I.</given-names></name><name><surname>Husain</surname><given-names>H.</given-names></name><name><surname>Ali</surname><given-names>M.A.B.M.</given-names></name><name><surname>Marufuzzaman</surname><given-names>M.</given-names></name></person-group><article-title>Performance analysis of Bluetooth Zigbee and Wi-Fi protocols in 2.4 GHz multi-standard Zero-IF receiver</article-title><source>Przeglad Elektrotechniczny</source><year>2013</year><volume>89</volume><fpage>225</fpage><lpage>228</lpage></element-citation></ref><ref id="B14-sensors-19-04980"><label>14.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ni</surname><given-names>W.</given-names></name><name><surname>Wang</surname><given-names>Z.X.</given-names></name></person-group><article-title>Indoor location algorithm based on the measurement of the received signal strength</article-title><source>Front. Electr. Electron. Eng. China</source><year>2006</year><volume>1</volume><fpage>48</fpage><lpage>52</lpage><pub-id pub-id-type="doi">10.1007/s11460-005-0008-6</pub-id></element-citation></ref><ref id="B15-sensors-19-04980"><label>15.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dardari</surname><given-names>D.</given-names></name><name><surname>Conti</surname><given-names>A.</given-names></name><name><surname>Ferner</surname><given-names>U.</given-names></name><name><surname>Giorgetti</surname><given-names>A.</given-names></name><name><surname>Win</surname><given-names>M.Z.</given-names></name></person-group><article-title>Ranging with ultrawide bandwidth signals in multipath environments</article-title><source>Proc. IEEE</source><year>2009</year><volume>97</volume><fpage>404</fpage><lpage>426</lpage><pub-id pub-id-type="doi">10.1109/JPROC.2008.2008846</pub-id></element-citation></ref><ref id="B16-sensors-19-04980"><label>16.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guan</surname><given-names>L.</given-names></name><name><surname>Cong</surname><given-names>X.</given-names></name><name><surname>Sun</surname><given-names>Y.</given-names></name><name><surname>Gao</surname><given-names>Y.</given-names></name><name><surname>Iqbal</surname><given-names>U.</given-names></name><name><surname>Noureldin</surname><given-names>A.</given-names></name></person-group><article-title>Enhanced MEMS SINS Aided Pipeline Surveying System by Pipeline Junction Detection in Small Diameter Pipeline</article-title><source>IFAC-PapersOnLine</source><year>2017</year><volume>50</volume><fpage>3560</fpage><lpage>3565</lpage><pub-id pub-id-type="doi">10.1016/j.ifacol.2017.08.962</pub-id></element-citation></ref><ref id="B17-sensors-19-04980"><label>17.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Krishnan</surname><given-names>S.</given-names></name><name><surname>Sharma</surname><given-names>P.</given-names></name><name><surname>Guoping</surname><given-names>Z.</given-names></name><name><surname>Woon</surname><given-names>O.H.</given-names></name></person-group><article-title>A UWB based localization system for indoor robot navigation</article-title><source>Proceedings of the IEEE International Conference Ultra-Wideband</source><conf-loc>Singapore</conf-loc><conf-date>24&#x02013;26 September 2007</conf-date><fpage>77</fpage><lpage>82</lpage></element-citation></ref><ref id="B18-sensors-19-04980"><label>18.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Baala</surname><given-names>O.</given-names></name><name><surname>Zheng</surname><given-names>Y.</given-names></name><name><surname>Caminada</surname><given-names>A.</given-names></name></person-group><article-title>The impact of AP placement in WLAN-based indoor positioning system</article-title><source>Proceedings of the 8th International Conference on Networks</source><conf-loc>Gosier, Guadeloupe</conf-loc><conf-date>1&#x02013;6 March 2009</conf-date><fpage>12</fpage><lpage>17</lpage></element-citation></ref><ref id="B19-sensors-19-04980"><label>19.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mahfouz</surname><given-names>M.R.</given-names></name><name><surname>Kuhn</surname><given-names>M.J.</given-names></name><name><surname>To</surname><given-names>G.</given-names></name><name><surname>Fathy</surname><given-names>A.E.</given-names></name></person-group><article-title>Integration of UWB and wireless pressure mapping in surgical navigation</article-title><source>IEEE Trans. Microw. Theory Tech.</source><year>2009</year><volume>57</volume><fpage>2550</fpage><lpage>2564</lpage><pub-id pub-id-type="doi">10.1109/TMTT.2009.2029721</pub-id></element-citation></ref><ref id="B20-sensors-19-04980"><label>20.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abdulrahman</surname><given-names>A.</given-names></name><name><surname>Abdulmalik</surname><given-names>A.S.</given-names></name><name><surname>Mansour</surname><given-names>A.</given-names></name><name><surname>Ahmad</surname><given-names>A.</given-names></name><name><surname>Suheer</surname><given-names>A.H.</given-names></name><name><surname>Mai</surname><given-names>A.A.</given-names></name><name><surname>Hend</surname><given-names>A.K.</given-names></name></person-group><article-title>Ultra wide band indoor positioning technologies: Analysis and recent advances</article-title><source>Sensors</source><year>2016</year><volume>16</volume><fpage>707</fpage></element-citation></ref><ref id="B21-sensors-19-04980"><label>21.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sobhani</surname><given-names>B.</given-names></name><name><surname>Zwick</surname><given-names>T.</given-names></name><name><surname>Chiani</surname><given-names>M.</given-names></name></person-group><article-title>Target TOA association with the Hough Transform in UWB radars</article-title><source>IEEE Trans. Aerosp. Electron. Syst.</source><year>2016</year><volume>52</volume><fpage>743</fpage><lpage>754</lpage><pub-id pub-id-type="doi">10.1109/TAES.2015.140872</pub-id></element-citation></ref><ref id="B22-sensors-19-04980"><label>22.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gong</surname><given-names>X.</given-names></name><name><surname>Zhang</surname><given-names>J.</given-names></name><name><surname>Fang</surname><given-names>J.</given-names></name></person-group><article-title>A modified nonlinear two-filter smoothing for high-precision airborne integrated GPS and inertial navigation</article-title><source>IEEE Trans. Instrum. Meas.</source><year>2015</year><volume>64</volume><fpage>3315</fpage><lpage>3322</lpage><pub-id pub-id-type="doi">10.1109/TIM.2015.2454672</pub-id></element-citation></ref><ref id="B23-sensors-19-04980"><label>23.</label><element-citation publication-type="web"><article-title>STM32 32-Bit Arm Cortex MCUs</article-title><comment>Available online: <ext-link ext-link-type="uri" xlink:href="https://www.st.com/en/microcontrollers-microprocessors/stm32-32-bit-arm-cortex-mcus.html">https://www.st.com/en/microcontrollers-microprocessors/stm32-32-bit-arm-cortex-mcus.html</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2008-04-21">(accessed on 21 April 2008)</date-in-citation></element-citation></ref><ref id="B24-sensors-19-04980"><label>24.</label><element-citation publication-type="web"><article-title>Razor_imu_9dof</article-title><comment>Available online: <ext-link ext-link-type="uri" xlink:href="http://wiki.ros.org/razor_imu_9dof">http://wiki.ros.org/razor_imu_9dof</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2013-07-11">(accessed on 11 July 2013)</date-in-citation></element-citation></ref><ref id="B25-sensors-19-04980"><label>25.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Kais</surname><given-names>M.</given-names></name><name><surname>Morin</surname><given-names>S.</given-names></name><name><surname>De La Fortelle</surname><given-names>A.</given-names></name><name><surname>Laugier</surname><given-names>C.</given-names></name></person-group><article-title>Geometrical model to drive vision systems with error propagation</article-title><source>Proceedings of the ICARCV 2004 Control, Automation, Robotics and Vision Conference</source><conf-loc>Kunming, China</conf-loc><conf-date>6&#x02013;9 December 2004</conf-date><volume>Volume 1</volume><fpage>143</fpage><lpage>148</lpage></element-citation></ref><ref id="B26-sensors-19-04980"><label>26.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sabatini</surname><given-names>A.M.</given-names></name></person-group><article-title>Quaternion-based extended Kalman filter for determining orientation by inertial and magnetic sensing</article-title><source>IEEE Trans. Biomed. Eng.</source><year>2006</year><volume>53</volume><fpage>1346</fpage><lpage>1356</lpage><pub-id pub-id-type="doi">10.1109/TBME.2006.875664</pub-id><?supplied-pmid 16830938?><pub-id pub-id-type="pmid">16830938</pub-id></element-citation></ref><ref id="B27-sensors-19-04980"><label>27.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Yun</surname><given-names>X.</given-names></name><name><surname>Lizarraga</surname><given-names>M.</given-names></name><name><surname>Bachmann</surname><given-names>E.R.</given-names></name><name><surname>McGhee</surname><given-names>R.B.</given-names></name></person-group><article-title>An improved quaternion-based Kalman filter for real-time tracking of rigid body orientation</article-title><source>Proceedings of the 2003 IEEE/RSJ International Conference on Intelligent Robots and Systems</source><conf-loc>Las Vegas, NV, USA</conf-loc><conf-date>27&#x02013;31 October 2003</conf-date></element-citation></ref><ref id="B28-sensors-19-04980"><label>28.</label><element-citation publication-type="patent"><person-group person-group-type="author"><name><surname>Zeng</surname><given-names>Y.</given-names></name><name><surname>Kirkland</surname><given-names>J.W.</given-names></name><name><surname>Anderson</surname><given-names>J.F.</given-names></name><name><surname>Leftin</surname><given-names>L.J.</given-names></name><name><surname>Briske</surname><given-names>R.W.</given-names></name></person-group><article-title>Methods and Systems for Implementing an Iterated Extended Kalman Filter within a Navigation System</article-title><source>U.S. Patent</source><patent>7873472 B2</patent><day>18</day><month>1</month><year>2011</year></element-citation></ref><ref id="B29-sensors-19-04980"><label>29.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tiano</surname><given-names>A.</given-names></name><name><surname>Sutton</surname><given-names>R.</given-names></name><name><surname>Lozowicki</surname><given-names>A.</given-names></name><name><surname>Naeem</surname><given-names>W.</given-names></name></person-group><article-title>Observer Kalman filter identification of an autonomous underwater vehicle</article-title><source>Control Eng. Pract.</source><year>2007</year><volume>15</volume><fpage>727</fpage><lpage>739</lpage><pub-id pub-id-type="doi">10.1016/j.conengprac.2006.08.004</pub-id></element-citation></ref></ref-list></back><floats-group><fig id="sensors-19-04980-f001" orientation="portrait" position="float"><label>Figure 1</label><caption><p>Structure diagram of the robot system.</p></caption><graphic xlink:href="sensors-19-04980-g001"/></fig><fig id="sensors-19-04980-f002" orientation="portrait" position="float"><label>Figure 2</label><caption><p>Movement track diagram of the robot in time <italic>t</italic>.</p></caption><graphic xlink:href="sensors-19-04980-g002"/></fig><fig id="sensors-19-04980-f003" orientation="portrait" position="float"><label>Figure 3</label><caption><p>Changing angle of the robot in time <italic>t</italic>.</p></caption><graphic xlink:href="sensors-19-04980-g003"/></fig><fig id="sensors-19-04980-f004" orientation="portrait" position="float"><label>Figure 4</label><caption><p>Delivery robot motion trajectory simulation diagram.</p></caption><graphic xlink:href="sensors-19-04980-g004"/></fig><fig id="sensors-19-04980-f005" orientation="portrait" position="float"><label>Figure 5</label><caption><p>Intersection coordinates.</p></caption><graphic xlink:href="sensors-19-04980-g005"/></fig><fig id="sensors-19-04980-f006" orientation="portrait" position="float"><label>Figure 6</label><caption><p>Schematic of time difference of arrival (TDOA) positioning algorithm.</p></caption><graphic xlink:href="sensors-19-04980-g006"/></fig><fig id="sensors-19-04980-f007" orientation="portrait" position="float"><label>Figure 7</label><caption><p>Delivery robot control flowchart.</p></caption><graphic xlink:href="sensors-19-04980-g007"/></fig><fig id="sensors-19-04980-f008" orientation="portrait" position="float"><label>Figure 8</label><caption><p>Food Delivery Robot.</p></caption><graphic xlink:href="sensors-19-04980-g008"/></fig><fig id="sensors-19-04980-f009" orientation="portrait" position="float"><label>Figure 9</label><caption><p>Delivery robot operation site diagram.</p></caption><graphic xlink:href="sensors-19-04980-g009"/></fig><fig id="sensors-19-04980-f010" orientation="portrait" position="float"><label>Figure 10</label><caption><p>The tracks of the delivery robot positioned by the ultra-wide band (UWB) positioning system.</p></caption><graphic xlink:href="sensors-19-04980-g010a"/><graphic xlink:href="sensors-19-04980-g010b"/></fig><fig id="sensors-19-04980-f011" orientation="portrait" position="float"><label>Figure 11</label><caption><p>Heading angle changes measured by one of five inertial measurement units (IMUs).</p></caption><graphic xlink:href="sensors-19-04980-g011"/></fig><fig id="sensors-19-04980-f012" orientation="portrait" position="float"><label>Figure 12</label><caption><p>Heading angle changes measured by other four IMUs.</p></caption><graphic xlink:href="sensors-19-04980-g012a"/><graphic xlink:href="sensors-19-04980-g012b"/></fig><fig id="sensors-19-04980-f013" orientation="portrait" position="float"><label>Figure 13</label><caption><p>Schematic diagram of the change in the heading angle calculated by the improved odometer positioning method.</p></caption><graphic xlink:href="sensors-19-04980-g013a"/><graphic xlink:href="sensors-19-04980-g013b"/></fig><fig id="sensors-19-04980-f014" orientation="portrait" position="float"><label>Figure 14</label><caption><p>Track of the delivery robot positioned by the improved odometer positioning method.</p></caption><graphic xlink:href="sensors-19-04980-g014"/></fig><fig id="sensors-19-04980-f015" orientation="portrait" position="float"><label>Figure 15</label><caption><p>Extended Kalman filter (EKF) fused coordinates and original coordinates comparison.</p></caption><graphic xlink:href="sensors-19-04980-g015"/></fig><fig id="sensors-19-04980-f016" orientation="portrait" position="float"><label>Figure 16</label><caption><p>Positioning error comparison.</p></caption><graphic xlink:href="sensors-19-04980-g016"/></fig><table-wrap id="sensors-19-04980-t001" orientation="portrait" position="float"><object-id pub-id-type="pii">sensors-19-04980-t001_Table 1</object-id><label>Table 1</label><caption><p>The maximum error statistical results of the three positioning methods.</p></caption><table frame="hsides" rules="groups"><thead><tr><th colspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">Positioning Methods Experimental Cases</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">IMU</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">UWB</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">EKF</th></tr></thead><tbody><tr><td rowspan="3" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">Situation I</td><td align="center" valign="middle" rowspan="1" colspan="1">1(a)</td><td align="center" valign="middle" rowspan="1" colspan="1">63.1 cm</td><td align="center" valign="middle" rowspan="1" colspan="1">59.6 cm</td><td align="center" valign="middle" rowspan="1" colspan="1">16.2 cm</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">2(b)</td><td align="center" valign="middle" rowspan="1" colspan="1">79.9 cm</td><td align="center" valign="middle" rowspan="1" colspan="1">58.4 cm</td><td align="center" valign="middle" rowspan="1" colspan="1">14.2 cm</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">3(c)</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">63.3 cm</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">62.6 cm</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">14.7 cm</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">Situation II</td><td align="center" valign="middle" rowspan="1" colspan="1">4(d)</td><td align="center" valign="middle" rowspan="1" colspan="1">59.4 cm</td><td align="center" valign="middle" rowspan="1" colspan="1">103.5 cm</td><td align="center" valign="middle" rowspan="1" colspan="1">15.5 cm</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">5(e)</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">61.3 cm</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">82.3 cm</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">15.0 cm</td></tr></tbody></table></table-wrap></floats-group></article>