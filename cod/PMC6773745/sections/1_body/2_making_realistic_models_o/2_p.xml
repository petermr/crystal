<?xml version="1.0" encoding="UTF-8"?>
<p id="Par7">A key difficulty is always going to be that of knowing how much to trust the answer. I do not think it’s yet clear, for example, how large is the error bar on the hierarchical structure of PMN. Even if experimental uncertainties were propagated fully—and there are good reasons why it is difficult to do so for e.g., PDF measurements—determining the uncertainty in emergent features is an even greater and less well-defined challenge. Checking for consistency in independent instances of a complex modelling process is of course good practice. Yet consistency is a necessary-but-not-sufficient criterion for correct structure solution: stochastic methods such as RMC are biased towards configurationally accessible solutions, whether or not they are actually physical
 <sup>
  <xref ref-type="bibr" rid="CR5">5</xref>
 </sup>. Deterministic alternatives, such as the Diffpy-CMI approach
 <sup>
  <xref ref-type="bibr" rid="CR6">6</xref>
 </sup>, are also not immune from uniqueness problems, and suffer more generally from the need to identify ab initio a suitable nanostructure model. In particular, one never knows whether a more physical model may exist and account for the same experimental observables equally well (or indeed more accurately
 <sup>
  <xref ref-type="bibr" rid="CR7">7</xref>
 </sup>).
</p>
